> kind create cluster --name=XPTO

> kubectl cluster-info --context kind-kind

Testando pra ver se o kbectl está apontando pro cluster criado

> kubectl get nodes
> docker ps

Pra deletar um cluster

> kind get clusters
> kind delete clusters <CLUSTER-NAME>


Criando com arquivo yaml (multiplos nodes)
> kind create cluster --config=k8s/kind.yaml --name=fullcycle


Conseguimos trocar o cluster (pra um em nuvem)
> kubectl config get-clusters
> kubectl config use-context <NAME>

> kubectl config get-contexts
> kubectl config use-context <NAME>

Aplicando um Pod
> kubectl apply -f k8s/pod.yaml

> kubectl port-forward pod/<POD-NAME> 8000:80
> kubectl get pod
> kubectl delete pod <POD-NAME>


Rollout
> kubectl rollout history deployment <DEPLOYMENT-NAME>
> kubectl rollout undo deployment <DEPLOYMENT-NAME> --to-revision=1 


Service
> kubectl get svc
> kubectl port-forward svc/pyserver-service 8080/8080


> kubectl proxy --port=8080


Configmap
> kubectl apply -f k8s/configmap-env.yaml


Acessando um Pod
> kubectl exet -it <POD-NAME> -- bash


Acessando o Log do Pod
> kubectl logs <POD-NAME>


Probe, verificando o liveness da aplicação:

> kubectl apply -f k8s/deployment-probe.yaml && watch -n1 kubectl get pods
> kubectl describe pod <POD-NAME>


Verificar o consumo de CPU e Memória

> kubectl top pod <POD-NAME>
> watch -n1 kubectl get hpa


Fortio

> kubectl run -it fortio --rm --image=fortio/fortio -- load -qps 800 -t 120s -c 70 "http://pyserver-service/health"


Storage

> kubectl get storageclass

> kubectl get pv      # PersistentVolume
> kubectl get pvc     # PersistentVolumeClaim


Verificando a persistencia

> kubectl get pod
> kubectl exec -it <POD-NAME> --bash
# criar arquivo na pasta persistentes
> kubectl delete pod <POD-NAME>


Utilizando o headless service, chamando o pod pelo dns:

> kubectl get statefulset
> kubectl get endpoints <SERVICE-NAME>
> kubectl exec -it <POD-NAME> -- bash
  > ping <POD-NAME>.<SERVICE-NAME>